{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import datetime\n",
    "import pickle\n",
    "from multiprocessing import Queue\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from config import CFG\n",
    "CFG=CFG()\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler():\n",
    "    def __init__(self, *chrome_options, url=CFG.URL2, window_size=CFG.WINDOW_SIZE):\n",
    "        # sourcery skip: remove-pass-body\n",
    "        self.url = url\n",
    "        self.window_size = window_size\n",
    "        if chrome_options:\n",
    "            self.options = webdriver.ChromeOptions()\n",
    "            for option in chrome_options:\n",
    "                self.options.add_argument(option)\n",
    "            opt = True\n",
    "        else: opt = False\n",
    "        self.opt = opt\n",
    "\n",
    "    def connect(self):\n",
    "        print(\"Connecting to Selenium\")\n",
    "        if self.opt:\n",
    "            self.driver = webdriver.Chrome(options=self.options)\n",
    "        else:\n",
    "            self.driver = webdriver.Chrome()\n",
    "        self.driver.get(self.url)\n",
    "        self.driver.set_window_size(self.window_size[0], self.window_size[1])\n",
    "        time.sleep(40)\n",
    "        self.driver.switch_to.frame(0)\n",
    "        self.driver.find_element(By.CSS_SELECTOR, \"#tab_container > li:nth-child(3) > a\").click() # '//*[@id=\"tab_container\"]/li[3]/a'\n",
    "        self.pages = self.driver.find_element(By.CLASS_NAME,\n",
    "            'last-page'\n",
    "        ).text  #table-ogu706xi71r > div.previous-next-container > div > div.last-page  //*[@id=\"table-ogu706xi71r\"]/div[3]/div/div[2]\n",
    "        print(\"Successfully connected to Selenium\")\n",
    "\n",
    "    def __del__(self):\n",
    "        self.driver.quit()\n",
    "\n",
    "    def click_button(self, selector, value, sleep_time=0):\n",
    "        button = self.driver.find_element(selector, value)\n",
    "        self.driver.execute_script(\"arguments[0].click();\", button)\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    def make_df(self):\n",
    "        page_source = self.driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        return pd.read_html(str(table))[0]\n",
    "\n",
    "    def collect_data(self, num_clicks=None, start_page=0, save=True):\n",
    "        previous_date = None\n",
    "        print(\"Starting data collection\")\n",
    "        if num_clicks is None:\n",
    "            num_clicks = int(self.pages) - 1\n",
    "        if start_page != 0:\n",
    "            self.driver.find_element(By.CLASS_NAME, \"current-page\").click()\n",
    "            self.driver.find_element(By.CLASS_NAME, \"current-page\").send_keys(str(start_page))\n",
    "            self.driver.find_element(By.CLASS_NAME, \"current-page\").send_keys(Keys.ENTER)\n",
    "        dfs = [self.make_df()]\n",
    "        for i in range(num_clicks):\n",
    "            WebDriverWait(self.driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"next-page\"))\n",
    "            )\n",
    "            self.click_button(By.CLASS_NAME, \"next-page\", 0.1)\n",
    "            dfs.append(self.make_df())\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Collected {i} pages\")\n",
    "            if i % 500 == 0:\n",
    "                if previous_date is not None:\n",
    "                    try:\n",
    "                        os.remove(f'data_files/df_lists-{previous_date}.pkl')\n",
    "                    except Exception as e:\n",
    "                        print(f'Unable to delete previous saved file because of: {e}')\n",
    "                if save:\n",
    "                    print(\"Saving data\")\n",
    "                    previous_date = datetime.date.today()\n",
    "                    pickle.dump(dfs, open(f'data_files/df_lists-{previous_date}.pkl', 'wb'))\n",
    "        print(\"Finished data collection\")\n",
    "        return pd.concat(dfs, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    def run(self, num_clicks=None, num_threads=1, save=True):\n",
    "        # sourcery skip: remove-pass-body, remove-redundant-if\n",
    "        if num_threads > 1:\n",
    "            pass\n",
    "        else:\n",
    "            df = self.collect_data(num_clicks, save=save)\n",
    "        self.teardown_method()\n",
    "        df.columns = df.columns.str.replace('  ', ' ')\n",
    "        df = df.dropna(how='all')\n",
    "        if save:\n",
    "            today = datetime.date.today()\n",
    "            df.to_csv(f'/data_files/scraped_data-{today}.csv', index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = Crawler()#(*CFG.CHROME_OPTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Selenium\n",
      "Successfully connected to Selenium\n"
     ]
    }
   ],
   "source": [
    "crawler.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m crawler\u001b[39m.\u001b[39mrun(num_clicks\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, save\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [3], line 80\u001b[0m, in \u001b[0;36mCrawler.run\u001b[1;34m(self, num_clicks, num_threads, save)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_data(num_clicks, save\u001b[39m=\u001b[39;49msave)\n\u001b[0;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteardown_method()\n\u001b[0;32m     82\u001b[0m df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m  \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [3], line 55\u001b[0m, in \u001b[0;36mCrawler.collect_data\u001b[1;34m(self, num_clicks, start_page, save)\u001b[0m\n\u001b[0;32m     53\u001b[0m dfs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_df()]\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_clicks):\n\u001b[1;32m---> 55\u001b[0m     WebDriverWait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdriver, \u001b[39m5\u001b[39;49m)\u001b[39m.\u001b[39;49muntil(\n\u001b[0;32m     56\u001b[0m         EC\u001b[39m.\u001b[39;49melement_to_be_clickable((By\u001b[39m.\u001b[39;49mCLASS_NAME, \u001b[39m\"\u001b[39;49m\u001b[39mnext-page\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclick_button(By\u001b[39m.\u001b[39mCLASS_NAME, \u001b[39m\"\u001b[39m\u001b[39mnext-page\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[0;32m     59\u001b[0m     dfs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_df())\n",
      "File \u001b[1;32mc:\\Users\\broug\\mambaforge\\envs\\drugs\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m>\u001b[39m end_time:\n\u001b[0;32m     94\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "crawler.run(num_clicks=5, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3126'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawler.pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.put_nowait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drugs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d943b4ed689cbeb84325fac1ea736cb4f575bb5014cc41287581e934615cc6ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
